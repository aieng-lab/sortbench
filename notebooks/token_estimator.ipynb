{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token Estimator\n",
    "\n",
    "A notebook to aid with the cost estimations for this benchmarks. We estimate the number of tokens based on GPT-4o's tokenizer and then compute the API costs for various models based on current rates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we run the notebook from the top-level of the repo\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens for basic mode: 88430\n",
      "Total tokens for advanced mode: 319621\n",
      "Total tokens: 408051\n",
      "\n",
      "Model: gpt-4o\n",
      "Input costs: 0.17686\n",
      "Output costs: 0.8843\n",
      "Total costs: 1.0611599999999999\n",
      "\n",
      "Model: gpt-o1\n",
      "Input costs: 1.32645\n",
      "Output costs: 5.3058\n",
      "Total costs: 6.632249999999999\n",
      "\n",
      "Model: gpt-4o-mini\n",
      "Input costs: 0.0132645\n",
      "Output costs: 0.053058\n",
      "Total costs: 0.0663225\n",
      "\n",
      "Model: gpt-3.5-turbo\n",
      "Input costs: 0.26529\n",
      "Output costs: 0.53058\n",
      "Total costs: 0.7958700000000001\n",
      "\n",
      "Total costs: 8.555602499999999\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "from sortbench.util.data_utils import load_data_local\n",
    "\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "\n",
    "\n",
    "# estimate tokens for basic mode\n",
    "configs = load_data_local(file_path=\"benchmark_data\", name=\"sortbench\", mode=\"basic\", version=\"v1.0\")\n",
    "total_tokens_basic = 0\n",
    "for config in configs.values():\n",
    "    for list in config.values():\n",
    "        total_tokens_basic += len(enc.encode(f\"{list}\"))\n",
    "\n",
    "print(f\"Total tokens for basic mode: {total_tokens_basic}\")\n",
    "\n",
    "# estimate tokens for advanced mode\n",
    "configs = load_data_local(file_path=\"benchmark_data\", name=\"sortbench\", mode=\"advanced\", version=\"v1.0\")\n",
    "total_tokens_adv = 0\n",
    "for config in configs.values():\n",
    "    for list in config.values():\n",
    "        total_tokens_adv += len(enc.encode(f\"{list}\"))\n",
    "\n",
    "print(f\"Total tokens for advanced mode: {total_tokens_adv}\")\n",
    "\n",
    "print(f\"Total tokens: {total_tokens_basic + total_tokens_adv}\")\n",
    "print(\"\")\n",
    "\n",
    "model_costs = {\"gpt-4o\": {\"input\": 2.0, \"output\": 10.0},\n",
    "               \"gpt-o1\": {\"input\": 15.0, \"output\": 60.0},\n",
    "               \"gpt-4o-mini\": {\"input\": 0.15, \"output\": 0.6},\n",
    "               \"gpt-3.5-turbo\": {\"input\": 3.0, \"output\": 6.0}\n",
    "               }\n",
    "\n",
    "total_costs = 0\n",
    "for model, costs in model_costs.items():\n",
    "    costs_input = (total_tokens_basic * costs['input'] + total_tokens_adv * costs['input']) / 1000000\n",
    "    costs_output = (total_tokens_basic * costs['output'] + total_tokens_adv * costs['output']) / 1000000\n",
    "    costs_model = costs_input + costs_output    \n",
    "    total_costs += costs_model\n",
    "\n",
    "    print(f\"Model: {model}\")\n",
    "    print(f\"Input costs: {costs_input}\")\n",
    "    print(f\"Output costs: {costs_output}\")\n",
    "    print(f\"Total costs: {costs_model}\")\n",
    "    print(\"\")\n",
    "print(f\"Total costs: {total_costs}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
