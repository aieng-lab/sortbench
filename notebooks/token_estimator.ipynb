{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token Estimator\n",
    "\n",
    "A notebook to aid with the cost estimations for this benchmarks. We estimate the number of tokens based on GPT-4o's tokenizer and then compute the API costs for various models based on current rates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sherbold/git/sortbench\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sherbold/git/sortbench/.venv/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "# we run the notebook from the top-level of the repo\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens for basic mode: 88430\n",
      "Total tokens for advanced mode: 319621\n",
      "Total tokens for debug mode: 176512\n",
      "Total tokens: 584563\n",
      "\n",
      "Model: gpt-4o\n",
      "Input costs: 1.169126\n",
      "Output costs: 5.84563\n",
      "Total costs: 7.014756\n",
      "\n",
      "Model: gpt-o1\n",
      "Input costs: 8.768445\n",
      "Output costs: 35.07378\n",
      "Total costs: 43.842225\n",
      "\n",
      "Model: gpt-4o-mini\n",
      "Input costs: 0.08768445\n",
      "Output costs: 0.3507378\n",
      "Total costs: 0.43842225\n",
      "\n",
      "Model: gpt-3.5-turbo\n",
      "Input costs: 1.753689\n",
      "Output costs: 3.507378\n",
      "Total costs: 5.261067000000001\n",
      "\n",
      "Model: claude-opus\n",
      "Input costs: 8.768445\n",
      "Output costs: 43.842225\n",
      "Total costs: 52.61067\n",
      "\n",
      "Model: claude-sonnet\n",
      "Input costs: 1.753689\n",
      "Output costs: 8.768445\n",
      "Total costs: 10.522134\n",
      "\n",
      "Model: claude-haiku\n",
      "Input costs: 0.4676504\n",
      "Output costs: 2.338252\n",
      "Total costs: 2.8059024000000004\n",
      "\n",
      "Total costs (cloud): 122.49517664999999\n",
      "Model: llama3.1\n",
      "Input costs: 496.87854999999996\n",
      "Output costs: 701.4756\n",
      "Total costs: 1198.35415\n",
      "\n",
      "Model: gemma2\n",
      "Input costs: 233.82520000000002\n",
      "Output costs: 350.7378\n",
      "Total costs: 584.563\n",
      "\n",
      "Model: qwen2.5:\n",
      "Input costs: 496.87854999999996\n",
      "Output costs: 701.4756\n",
      "Total costs: 1198.35415\n",
      "\n",
      "Model: deepseekr1\n",
      "Input costs: 246.101023\n",
      "Output costs: 303.97276\n",
      "Total costs: 550.073783\n",
      "\n",
      "Total costs (local): 3531.3450829999992\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "from sortbench.util.data_utils import load_data_local\n",
    "\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "\n",
    "modes = [\"basic\", \"advanced\", \"debug\"]\n",
    "tokens_per_mode = {}\n",
    "\n",
    "for mode in modes:\n",
    "    configs = load_data_local(file_path=\"benchmark_data\", name=\"sortbench\", mode=mode, version=\"v1.0\")\n",
    "    for config in configs.values():\n",
    "        for list in config.values():\n",
    "            if mode not in tokens_per_mode:\n",
    "                tokens_per_mode[mode] = 0\n",
    "            tokens_per_mode[mode] += len(enc.encode(f\"{list}\"))\n",
    "    print(f\"Total tokens for {mode} mode: {tokens_per_mode[mode]}\")\n",
    "\n",
    "total_tokens = sum(tokens_per_mode.values())\n",
    "print(f\"Total tokens: {total_tokens}\")\n",
    "print()\n",
    "\n",
    "model_costs = {\"gpt-4o\": {\"input\": 2.0, \"output\": 10.0},\n",
    "               \"gpt-o1\": {\"input\": 15.0, \"output\": 60.0},\n",
    "               \"gpt-4o-mini\": {\"input\": 0.15, \"output\": 0.6},\n",
    "               \"gpt-3.5-turbo\": {\"input\": 3.0, \"output\": 6.0},\n",
    "               \"claude-opus\": {\"input\": 15.0, \"output\": 75.0},\n",
    "               \"claude-sonnet\": {\"input\": 3.0, \"output\": 15.0},\n",
    "               \"claude-haiku\": {\"input\": 0.8, \"output\": 4.0},\n",
    "               }\n",
    "\n",
    "total_costs = 0\n",
    "for model, costs in model_costs.items():\n",
    "    costs_input = (total_tokens * costs['input']) / 1000000\n",
    "    costs_output = (total_tokens * costs['output']) / 1000000\n",
    "    costs_model = costs_input + costs_output    \n",
    "    total_costs += costs_model\n",
    "\n",
    "    print(f\"Model: {model}\")\n",
    "    print(f\"Input costs: {costs_input}\")\n",
    "    print(f\"Output costs: {costs_output}\")\n",
    "    print(f\"Total costs: {costs_model}\")\n",
    "    print(\"\")\n",
    "print(f\"Total costs (cloud): {total_costs}\")\n",
    "print()\n",
    "\n",
    "local_model_costs = {\"llama3.1\": {\"input\": 0.00085, \"output\": 0.0012},\n",
    "                     \"gemma2\": {\"input\": 0.00040, \"output\": 0.0006},\n",
    "                     \"qwen2.5:\": {\"input\": 0.00085, \"output\": 0.0012},\n",
    "                     \"deepseekr1\": {\"input\": 0.000421, \"output\": 0.000520}\n",
    "                     }\n",
    "\n",
    "total_costs_local = 0\n",
    "for model, costs in local_model_costs.items():\n",
    "    costs_input = (total_tokens * costs['input'])\n",
    "    costs_output = (total_tokens * costs['output'])\n",
    "    costs_model = costs_input + costs_output\n",
    "    total_costs_local += costs_model\n",
    "\n",
    "    print(f\"Model: {model}\")\n",
    "    print(f\"Input costs: {costs_input}\")\n",
    "    print(f\"Output costs: {costs_output}\")\n",
    "    print(f\"Total costs: {costs_model}\")\n",
    "    print(\"\")\n",
    "\n",
    "print(f\"Total costs (local): {total_costs_local}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "850.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.00085*1000000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
